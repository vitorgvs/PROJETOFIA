version: "3.9"

services:

  minio:
      platform: linux/amd64
      image: fjardim/mds-minio
      container_name: minio
      command:  server --console-address ":9001" /data
      ports:
        - "9000:9000"
        - "9001:9001"
      hostname: minio
      environment:
        MINIO_ROOT_USER: admin
        MINIO_ROOT_PASSWORD: minioadmin
        MINIO_ACCESS_KEY: projeto_final
        MINIO_SECRET_KEY: projeto_final
      volumes:
        - ./minio/data1:/data
        - ./scripts:/scripts
      networks:
        rede_sptrans:

  spark:
    platform: linux/amd64
    image: fjardim/mds-spark
    container_name: spark
    hostname: spark
    command:
      - /bin/sh
      - -c
      - |
        /usr/local/spark/sbin/start-master.sh
        start-notebook.sh --NotebookApp.token=''
    ports:
      - "8889:8888"
      - "4040:4040"
      - "4041:4041"
      - "4042:4042"
      - "4043:4043"
      - "8180:8080"
      - "7077:7077"
    volumes:
      - ./SparkConfigs/apacheSpark/util:/util
      - ./IntegratedPipeline/work:/home/user
      - ./SparkConfigs/apacheSpark/env:/env
    networks:
      - rede_sptrans

  spark-master:
    platform: linux/amd64
    image: fjardim/mds-spark
    container_name: spark-master
    hostname: spark-master
    command:
      - /bin/sh
      - -c
      - |
        /usr/local/spark/sbin/start-master.sh
        start-notebook.sh --NotebookApp.token=''
    ports:
      - "8890:8888"
      - "8181:8080"
      - "7078:7077"
    volumes:
      - ./SparkConfigs/apacheSpark/util:/util
      - ./SparkConfigs/apacheSpark/dados_gtfs:/dados_gtfs
      - ./SparkConfigs/apacheSpark/work:/home/user
      - ./SparkConfigs/apacheSpark/env:/env
    networks:
      - rede_sptrans

  spark-worker:
    platform: linux/amd64
    image: fjardim/mds-spark
    container_name: spark-worker
    hostname: spark-worker
    command:
      - /bin/sh
      - -c
      - |
        /usr/local/spark/sbin/start-worker.sh spark-master:7077
        start-notebook.sh --NotebookApp.token=''
    env_file:
      - ./SparkConfigs/apacheSpark/env/jupyter.env
    ports:
      - "5040:4040"
      - "8881:8081"
    volumes:
      - ./SparkConfigs/apacheSpark/util:/util
      - ./SparkConfigs/apacheSpark/work:/home/user
      - ./SparkConfigs/apacheSpark/dados_gtfs:/dados_gtfs
    environment:
      SPARK_MASTER: spark-master
    depends_on:
      - spark-master
    networks:
      - rede_sptrans

  postgres_airflow:
    image: postgres:13
    container_name: postgres_airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    networks:
      - rede_sptrans

  webserver:
    build:
      context: .              
      dockerfile: Airflow/docker/Dockerfile
    platform: linux/amd64
    container_name: webserver
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres_airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY:-LBi3PfqopCGRKZlFz2mXEjOCgxBtYy7q_Q3vF3rcUeA=}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${FERNET_KEY:-LBi3PfqopCGRKZlFz2mXEjOCgxBtYy7q_Q3vF3rcUeA2}
      AIRFLOW__CORE__LOAD_EXAMPLES: "True"
      AIRFLOW_CONN_SPARK_DEFAULT: 'spark://spark-master:7077'
    volumes:
      - ./Airflow/dags:/opt/airflow/dags
      - ./Airflow/requirements.txt:/requirements.txt
    ports:
      - "8080:8080"
    depends_on:
      - postgres_airflow
    networks:
      - rede_sptrans
    command: >
      bash -c "pip install -r /requirements.txt &&
               airflow db init &&
               airflow webserver"

  scheduler:
    build:
      context: .              
      dockerfile: Airflow/docker/Dockerfile
    platform: linux/amd64
    container_name: scheduler
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres_airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY:-LBi3PfqopCGRKZlFz2mXEjOCgxBtYy7q_Q3vF3rcUeA=}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${FERNET_KEY:-LBi3PfqopCGRKZlFz2mXEjOCgxBtYy7q_Q3vF3rcUeA2}
    volumes:
      - ./Airflow/dags:/opt/airflow/dags
      - ./Airflow/requirements.txt:/requirements.txt
    depends_on:
      - postgres_airflow
    networks:
      - rede_sptrans
    command: >
      bash -c "pip install -r /requirements.txt &&
               airflow scheduler"

  pgadmin:
    image: dpage/pgadmin4:${PAGADMIN_VERSION:-7.7}
    container_name: pgadmin_container
    environment:
      PGADMIN_DEFAULT_EMAIL: lab-pgadmin4@pgadmin.org
      PGADMIN_DEFAULT_PASSWORD: postgres
    ports:
      - "5433:80"
    depends_on:
      - postgres_airflow
    networks:
      - rede_sptrans

networks:
  rede_sptrans:
    driver: bridge

volumes:
  minio_storage:
